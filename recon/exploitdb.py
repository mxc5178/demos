#!/usr/bin/env python

##
##  DEPENDENCIES
##
##  BeautifulSoup
##
##      http://www.crummy.com/software/BeautifulSoup/
##      download ... decompress
##      python setup.py install
##

if __name__ == '__main__':

    from bs4 import BeautifulSoup as BS
    import urllib2
    import os

    path = os.path.join(os.getcwd(), 'data', 'servers.txt')
    with open(path, 'r') as f:
        for line in f:

            server = line.strip()

            if not server == '' and not server == 'Unknown':
                num = 1

                for num in range (1,10,1):
                    try:
                        response = urllib2.urlopen('http://www.exploit-db.com/search/?action=search&filter_page=' + str(num) +'&filter_exploit_text=' + server)

                        soup = BS(response)
                        rows = soup.findAll('td', {'class': 'list_explot_description'})
                        if len(rows) > 0:
                            for row in rows:
                                ## 
                                ## <server string>:<vulnerability>:<reference>
                                ##
                                print '%s:%s:%s'%(server, row.a.get_text().strip(), row.a.get('href').strip())

                        else:
                            break
                    
                        num += 1
                    except Exception, e:
                        pass
